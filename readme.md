# Generative AI with AWS â€“ Text Generation Parameters Lab

This repository contains hands-on tasks focused on **controlling Large Language Model (LLM) outputs using Amazon Bedrock text generation parameters**.  
The goal of this lab is to move beyond understanding concepts and **produce concrete, production-ready outputs**.

---

## ğŸ¯ Lab Objectives

By completing this lab, participants will be able to:

- Produce **deterministic, repeatable LLM outputs**
- Generate **creative, marketing-style content** using parameter tuning
- Control **response length and cost** using token limits
- Select the **right model and configuration** for a real-world use case
- Create **reusable prompt templates** ready for automation and RAG pipelines

---

## ğŸ§  Concepts Covered

- Temperature
- Max tokens
- Prompt vs parameter control
- Model behavior differences
- Production-readiness considerations

---

## â± Estimated Duration

**30â€“40 minutes**

---

## ğŸ“¦ Prerequisites

- AWS account with **Amazon Bedrock access enabled**
- IAM permissions for:
