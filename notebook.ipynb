{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa4f6e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:__main__:Got 124 foundation models.\n",
      "INFO:__main__:Done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: NVIDIA Nemotron Nano 12B v2 VL BF16\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/nvidia.nemotron-nano-12b-v2\",\n",
      "  \"modelId\": \"nvidia.nemotron-nano-12b-v2\",\n",
      "  \"modelName\": \"NVIDIA Nemotron Nano 12B v2 VL BF16\",\n",
      "  \"providerName\": \"NVIDIA\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Sonnet 4\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-sonnet-4-20250514-v1:0\",\n",
      "  \"modelName\": \"Claude Sonnet 4\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Haiku 4.5\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
      "  \"modelName\": \"Claude Haiku 4.5\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: gpt-oss-120b\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/openai.gpt-oss-120b-1:0\",\n",
      "  \"modelId\": \"openai.gpt-oss-120b-1:0\",\n",
      "  \"modelName\": \"gpt-oss-120b\",\n",
      "  \"providerName\": \"OpenAI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Creative Upscale\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-creative-upscale-v1:0\",\n",
      "  \"modelId\": \"stability.stable-creative-upscale-v1:0\",\n",
      "  \"modelName\": \"Stable Image Creative Upscale\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Qwen3 Next 80B A3B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/qwen.qwen3-next-80b-a3b\",\n",
      "  \"modelId\": \"qwen.qwen3-next-80b-a3b\",\n",
      "  \"modelName\": \"Qwen3 Next 80B A3B\",\n",
      "  \"providerName\": \"Qwen\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Amazon Nova Multimodal Embeddings\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-2-multimodal-embeddings-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-2-multimodal-embeddings-v1:0\",\n",
      "  \"modelName\": \"Amazon Nova Multimodal Embeddings\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"AUDIO\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nemotron Nano 3 30B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/nvidia.nemotron-nano-3-30b\",\n",
      "  \"modelId\": \"nvidia.nemotron-nano-3-30b\",\n",
      "  \"modelName\": \"Nemotron Nano 3 30B\",\n",
      "  \"providerName\": \"NVIDIA\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: MiniMax M2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/minimax.minimax-m2\",\n",
      "  \"modelId\": \"minimax.minimax-m2\",\n",
      "  \"modelName\": \"MiniMax M2\",\n",
      "  \"providerName\": \"MiniMax\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Voxtral Mini 3B 2507\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.voxtral-mini-3b-2507\",\n",
      "  \"modelId\": \"mistral.voxtral-mini-3b-2507\",\n",
      "  \"modelName\": \"Voxtral Mini 3B 2507\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"SPEECH\",\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Pro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-pro-v1:0\",\n",
      "  \"modelName\": \"Nova Pro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Remove Background\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-remove-background-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-remove-background-v1:0\",\n",
      "  \"modelName\": \"Stable Image Remove Background\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Control Sketch\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-control-sketch-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-control-sketch-v1:0\",\n",
      "  \"modelName\": \"Stable Image Control Sketch\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova 2 Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-2-lite-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-2-lite-v1:0\",\n",
      "  \"modelName\": \"Nova 2 Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova 2 Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-2-lite-v1:0:256k\",\n",
      "  \"modelId\": \"amazon.nova-2-lite-v1:0:256k\",\n",
      "  \"modelName\": \"Nova 2 Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Conservative Upscale\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-conservative-upscale-v1:0\",\n",
      "  \"modelId\": \"stability.stable-conservative-upscale-v1:0\",\n",
      "  \"modelName\": \"Stable Image Conservative Upscale\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Gemma 3 12B IT\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/google.gemma-3-12b-it\",\n",
      "  \"modelId\": \"google.gemma-3-12b-it\",\n",
      "  \"modelName\": \"Gemma 3 12B IT\",\n",
      "  \"providerName\": \"Google\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Search and Recolor\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-search-recolor-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-search-recolor-v1:0\",\n",
      "  \"modelName\": \"Stable Image Search and Recolor\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Kimi K2 Thinking\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/moonshot.kimi-k2-thinking\",\n",
      "  \"modelId\": \"moonshot.kimi-k2-thinking\",\n",
      "  \"modelName\": \"Kimi K2 Thinking\",\n",
      "  \"providerName\": \"Moonshot AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral Large 3\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-3-675b-instruct\",\n",
      "  \"modelId\": \"mistral.mistral-large-3-675b-instruct\",\n",
      "  \"modelName\": \"Mistral Large 3\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Pegasus v1.2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/twelvelabs.pegasus-1-2-v1:0\",\n",
      "  \"modelId\": \"twelvelabs.pegasus-1-2-v1:0\",\n",
      "  \"modelName\": \"Pegasus v1.2\",\n",
      "  \"providerName\": \"TwelveLabs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\",\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova 2 Sonic\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-2-sonic-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-2-sonic-v1:0\",\n",
      "  \"modelName\": \"Nova 2 Sonic\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"SPEECH\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"SPEECH\",\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Qwen3 32B (dense)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/qwen.qwen3-32b-v1:0\",\n",
      "  \"modelId\": \"qwen.qwen3-32b-v1:0\",\n",
      "  \"modelName\": \"Qwen3 32B (dense)\",\n",
      "  \"providerName\": \"Qwen\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Ministral 14B 3.0\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.ministral-3-14b-instruct\",\n",
      "  \"modelId\": \"mistral.ministral-3-14b-instruct\",\n",
      "  \"modelName\": \"Ministral 14B 3.0\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Palmyra X5\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/writer.palmyra-x5-v1:0\",\n",
      "  \"modelId\": \"writer.palmyra-x5-v1:0\",\n",
      "  \"modelName\": \"Palmyra X5\",\n",
      "  \"providerName\": \"Writer\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: NVIDIA Nemotron Nano 9B v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/nvidia.nemotron-nano-9b-v2\",\n",
      "  \"modelId\": \"nvidia.nemotron-nano-9b-v2\",\n",
      "  \"modelName\": \"NVIDIA Nemotron Nano 9B v2\",\n",
      "  \"providerName\": \"NVIDIA\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Ministral 3 8B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.ministral-3-8b-instruct\",\n",
      "  \"modelId\": \"mistral.ministral-3-8b-instruct\",\n",
      "  \"modelName\": \"Ministral 3 8B\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Voxtral Small 24B 2507\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.voxtral-small-24b-2507\",\n",
      "  \"modelId\": \"mistral.voxtral-small-24b-2507\",\n",
      "  \"modelName\": \"Voxtral Small 24B 2507\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"SPEECH\",\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: gpt-oss-20b\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/openai.gpt-oss-20b-1:0\",\n",
      "  \"modelId\": \"openai.gpt-oss-20b-1:0\",\n",
      "  \"modelName\": \"gpt-oss-20b\",\n",
      "  \"providerName\": \"OpenAI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Gemma 3 4B IT\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/google.gemma-3-4b-it\",\n",
      "  \"modelId\": \"google.gemma-3-4b-it\",\n",
      "  \"modelName\": \"Gemma 3 4B IT\",\n",
      "  \"providerName\": \"Google\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Fast Upscale\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-fast-upscale-v1:0\",\n",
      "  \"modelId\": \"stability.stable-fast-upscale-v1:0\",\n",
      "  \"modelName\": \"Stable Image Fast Upscale\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Erase Object\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-erase-object-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-erase-object-v1:0\",\n",
      "  \"modelName\": \"Stable Image Erase Object\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: GPT OSS Safeguard 120B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/openai.gpt-oss-safeguard-120b\",\n",
      "  \"modelId\": \"openai.gpt-oss-safeguard-120b\",\n",
      "  \"modelName\": \"GPT OSS Safeguard 120B\",\n",
      "  \"providerName\": \"OpenAI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Gemma 3 27B PT\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/google.gemma-3-27b-it\",\n",
      "  \"modelId\": \"google.gemma-3-27b-it\",\n",
      "  \"modelName\": \"Gemma 3 27B PT\",\n",
      "  \"providerName\": \"Google\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Control Structure\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-control-structure-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-control-structure-v1:0\",\n",
      "  \"modelName\": \"Stable Image Control Structure\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Marengo Embed 3.0\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/twelvelabs.marengo-embed-3-0-v1:0\",\n",
      "  \"modelId\": \"twelvelabs.marengo-embed-3-0-v1:0\",\n",
      "  \"modelName\": \"Marengo Embed 3.0\",\n",
      "  \"providerName\": \"TwelveLabs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"SPEECH\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\",\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Palmyra X4\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/writer.palmyra-x4-v1:0\",\n",
      "  \"modelId\": \"writer.palmyra-x4-v1:0\",\n",
      "  \"modelName\": \"Palmyra X4\",\n",
      "  \"providerName\": \"Writer\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Sonnet 4.5\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-sonnet-4-5-20250929-v1:0\",\n",
      "  \"modelName\": \"Claude Sonnet 4.5\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Marengo Embed v2.7\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/twelvelabs.marengo-embed-2-7-v1:0\",\n",
      "  \"modelId\": \"twelvelabs.marengo-embed-2-7-v1:0\",\n",
      "  \"modelName\": \"Marengo Embed v2.7\",\n",
      "  \"providerName\": \"TwelveLabs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"SPEECH\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Qwen3 VL 235B A22B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/qwen.qwen3-vl-235b-a22b\",\n",
      "  \"modelId\": \"qwen.qwen3-vl-235b-a22b\",\n",
      "  \"modelName\": \"Qwen3 VL 235B A22B\",\n",
      "  \"providerName\": \"Qwen\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Outpaint\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-outpaint-v1:0\",\n",
      "  \"modelId\": \"stability.stable-outpaint-v1:0\",\n",
      "  \"modelName\": \"Stable Image Outpaint\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Inpaint\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-inpaint-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-inpaint-v1:0\",\n",
      "  \"modelName\": \"Stable Image Inpaint\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Opus 4.1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-1-20250805-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-opus-4-1-20250805-v1:0\",\n",
      "  \"modelName\": \"Claude Opus 4.1\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Style Guide\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-style-guide-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-style-guide-v1:0\",\n",
      "  \"modelName\": \"Stable Image Style Guide\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Magistral Small 2509\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.magistral-small-2509\",\n",
      "  \"modelId\": \"mistral.magistral-small-2509\",\n",
      "  \"modelName\": \"Magistral Small 2509\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Style Transfer\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-style-transfer-v1:0\",\n",
      "  \"modelId\": \"stability.stable-style-transfer-v1:0\",\n",
      "  \"modelName\": \"Stable Image Style Transfer\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed v4\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-v4:0\",\n",
      "  \"modelId\": \"cohere.embed-v4:0\",\n",
      "  \"modelName\": \"Embed v4\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Ministral 3B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.ministral-3-3b-instruct\",\n",
      "  \"modelId\": \"mistral.ministral-3-3b-instruct\",\n",
      "  \"modelName\": \"Ministral 3B\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Opus 4.5\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-5-20251101-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-opus-4-5-20251101-v1:0\",\n",
      "  \"modelName\": \"Claude Opus 4.5\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Stable Image Search and Replace\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/stability.stable-image-search-replace-v1:0\",\n",
      "  \"modelId\": \"stability.stable-image-search-replace-v1:0\",\n",
      "  \"modelName\": \"Stable Image Search and Replace\",\n",
      "  \"providerName\": \"Stability AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Qwen3-Coder-30B-A3B-Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/qwen.qwen3-coder-30b-a3b-v1:0\",\n",
      "  \"modelId\": \"qwen.qwen3-coder-30b-a3b-v1:0\",\n",
      "  \"modelName\": \"Qwen3-Coder-30B-A3B-Instruct\",\n",
      "  \"providerName\": \"Qwen\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: GPT OSS Safeguard 20B\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/openai.gpt-oss-safeguard-20b\",\n",
      "  \"modelId\": \"openai.gpt-oss-safeguard-20b\",\n",
      "  \"modelName\": \"GPT OSS Safeguard 20B\",\n",
      "  \"providerName\": \"OpenAI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Large\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-tg1-large\",\n",
      "  \"modelId\": \"amazon.titan-tg1-large\",\n",
      "  \"modelName\": \"Titan Text Large\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Image Generator G1 v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-image-generator-v2:0\",\n",
      "  \"modelId\": \"amazon.titan-image-generator-v2:0\",\n",
      "  \"modelName\": \"Titan Image Generator G1 v2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\",\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:8k\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:8k\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:20k\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:20k\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:1000k\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:1000k\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0:mm\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0:mm\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Premier\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-premier-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-premier-v1:0\",\n",
      "  \"modelName\": \"Nova Premier\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Pro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:24k\",\n",
      "  \"modelId\": \"amazon.nova-pro-v1:0:24k\",\n",
      "  \"modelName\": \"Nova Pro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Pro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-pro-v1:0:300k\",\n",
      "  \"modelId\": \"amazon.nova-pro-v1:0:300k\",\n",
      "  \"modelName\": \"Nova Pro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"DISTILLATION\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:24k\",\n",
      "  \"modelId\": \"amazon.nova-lite-v1:0:24k\",\n",
      "  \"modelName\": \"Nova Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0:300k\",\n",
      "  \"modelId\": \"amazon.nova-lite-v1:0:300k\",\n",
      "  \"modelName\": \"Nova Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"DISTILLATION\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Lite\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-lite-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-lite-v1:0\",\n",
      "  \"modelName\": \"Nova Lite\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\",\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Canvas\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-canvas-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-canvas-v1:0\",\n",
      "  \"modelName\": \"Nova Canvas\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Reel\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-reel-v1:0\",\n",
      "  \"modelName\": \"Nova Reel\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Reel\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-reel-v1:1\",\n",
      "  \"modelId\": \"amazon.nova-reel-v1:1\",\n",
      "  \"modelName\": \"Nova Reel\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"VIDEO\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Micro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:24k\",\n",
      "  \"modelId\": \"amazon.nova-micro-v1:0:24k\",\n",
      "  \"modelName\": \"Nova Micro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Micro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0:128k\",\n",
      "  \"modelId\": \"amazon.nova-micro-v1:0:128k\",\n",
      "  \"modelName\": \"Nova Micro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\",\n",
      "    \"DISTILLATION\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Micro\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-micro-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-micro-v1:0\",\n",
      "  \"modelName\": \"Nova Micro\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Nova Sonic\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.nova-sonic-v1:0\",\n",
      "  \"modelId\": \"amazon.nova-sonic-v1:0\",\n",
      "  \"modelName\": \"Nova Sonic\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"SPEECH\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"SPEECH\",\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Embeddings v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-g1-text-02\",\n",
      "  \"modelId\": \"amazon.titan-embed-g1-text-02\",\n",
      "  \"modelName\": \"Titan Text Embeddings v2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Embeddings G1 - Text\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1:2:8k\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v1:2:8k\",\n",
      "  \"modelName\": \"Titan Embeddings G1 - Text\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Embeddings G1 - Text\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v1\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v1\",\n",
      "  \"modelName\": \"Titan Embeddings G1 - Text\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Embeddings V2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0:8k\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v2:0:8k\",\n",
      "  \"modelName\": \"Titan Text Embeddings V2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Text Embeddings V2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-text-v2:0\",\n",
      "  \"modelId\": \"amazon.titan-embed-text-v2:0\",\n",
      "  \"modelName\": \"Titan Text Embeddings V2\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Multimodal Embeddings G1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1:0\",\n",
      "  \"modelId\": \"amazon.titan-embed-image-v1:0\",\n",
      "  \"modelName\": \"Titan Multimodal Embeddings G1\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [\n",
      "    \"FINE_TUNING\"\n",
      "  ],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Titan Multimodal Embeddings G1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/amazon.titan-embed-image-v1\",\n",
      "  \"modelId\": \"amazon.titan-embed-image-v1\",\n",
      "  \"modelName\": \"Titan Multimodal Embeddings G1\",\n",
      "  \"providerName\": \"Amazon\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Jamba 1.5 Large\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-large-v1:0\",\n",
      "  \"modelId\": \"ai21.jamba-1-5-large-v1:0\",\n",
      "  \"modelName\": \"Jamba 1.5 Large\",\n",
      "  \"providerName\": \"AI21 Labs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Jamba 1.5 Mini\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/ai21.jamba-1-5-mini-v1:0\",\n",
      "  \"modelId\": \"ai21.jamba-1-5-mini-v1:0\",\n",
      "  \"modelName\": \"Jamba 1.5 Mini\",\n",
      "  \"providerName\": \"AI21 Labs\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Instant\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-instant-v1:2:100k\",\n",
      "  \"modelId\": \"anthropic.claude-instant-v1:2:100k\",\n",
      "  \"modelName\": \"Claude Instant\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:18k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:0:18k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:0:100k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:0:100k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:18k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:1:18k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-v2:1:200k\",\n",
      "  \"modelId\": \"anthropic.claude-v2:1:200k\",\n",
      "  \"modelName\": \"Claude\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:28k\",\n",
      "  \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0:28k\",\n",
      "  \"modelName\": \"Claude 3 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0:200k\",\n",
      "  \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0:200k\",\n",
      "  \"modelName\": \"Claude 3 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-sonnet-20240229-v1:0\",\n",
      "  \"modelName\": \"Claude 3 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:48k\",\n",
      "  \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0:48k\",\n",
      "  \"modelName\": \"Claude 3 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0:200k\",\n",
      "  \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0:200k\",\n",
      "  \"modelName\": \"Claude 3 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-haiku-20240307-v1:0\",\n",
      "  \"modelName\": \"Claude 3 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:12k\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0:12k\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:28k\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0:28k\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0:200k\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0:200k\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3 Opus\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-opus-20240229-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-opus-20240229-v1:0\",\n",
      "  \"modelName\": \"Claude 3 Opus\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.5 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
      "  \"modelName\": \"Claude 3.5 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\",\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.5 Sonnet v2\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
      "  \"modelName\": \"Claude 3.5 Sonnet v2\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.7 Sonnet\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
      "  \"modelName\": \"Claude 3.7 Sonnet\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude 3.5 Haiku\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-3-5-haiku-20241022-v1:0\",\n",
      "  \"modelName\": \"Claude 3.5 Haiku\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Claude Opus 4\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/anthropic.claude-opus-4-20250514-v1:0\",\n",
      "  \"modelId\": \"anthropic.claude-opus-4-20250514-v1:0\",\n",
      "  \"modelName\": \"Claude Opus 4\",\n",
      "  \"providerName\": \"Anthropic\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"LEGACY\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command R\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-v1:0\",\n",
      "  \"modelId\": \"cohere.command-r-v1:0\",\n",
      "  \"modelName\": \"Command R\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Command R+\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.command-r-plus-v1:0\",\n",
      "  \"modelId\": \"cohere.command-r-plus-v1:0\",\n",
      "  \"modelName\": \"Command R+\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed English\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3:0:512\",\n",
      "  \"modelId\": \"cohere.embed-english-v3:0:512\",\n",
      "  \"modelName\": \"Embed English\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed English\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-english-v3\",\n",
      "  \"modelId\": \"cohere.embed-english-v3\",\n",
      "  \"modelName\": \"Embed English\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed Multilingual\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3:0:512\",\n",
      "  \"modelId\": \"cohere.embed-multilingual-v3:0:512\",\n",
      "  \"modelName\": \"Embed Multilingual\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"PROVISIONED\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Embed Multilingual\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.embed-multilingual-v3\",\n",
      "  \"modelId\": \"cohere.embed-multilingual-v3\",\n",
      "  \"modelName\": \"Embed Multilingual\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"EMBEDDING\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Rerank 3.5\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/cohere.rerank-v3-5:0\",\n",
      "  \"modelId\": \"cohere.rerank-v3-5:0\",\n",
      "  \"modelName\": \"Rerank 3.5\",\n",
      "  \"providerName\": \"Cohere\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": false,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: DeepSeek-R1\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/deepseek.r1-v1:0\",\n",
      "  \"modelId\": \"deepseek.r1-v1:0\",\n",
      "  \"modelName\": \"DeepSeek-R1\",\n",
      "  \"providerName\": \"DeepSeek\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3 8B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-8b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-8b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3 8B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3 70B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-70b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-70b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3 70B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.1 8B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-8b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-1-8b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.1 8B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.1 70B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-1-70b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-1-70b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.1 70B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 11B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-11b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-11b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 11B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 90B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-90b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-90b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 90B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 1B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-1b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-1b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 1B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.2 3B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-2-3b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-2-3b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.2 3B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 3.3 70B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama3-3-70b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama3-3-70b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 3.3 70B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 4 Scout 17B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-scout-17b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama4-scout-17b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 4 Scout 17B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Llama 4 Maverick 17B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/meta.llama4-maverick-17b-instruct-v1:0\",\n",
      "  \"modelId\": \"meta.llama4-maverick-17b-instruct-v1:0\",\n",
      "  \"modelName\": \"Llama 4 Maverick 17B Instruct\",\n",
      "  \"providerName\": \"Meta\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral 7B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-7b-instruct-v0:2\",\n",
      "  \"modelId\": \"mistral.mistral-7b-instruct-v0:2\",\n",
      "  \"modelName\": \"Mistral 7B Instruct\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mixtral 8x7B Instruct\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mixtral-8x7b-instruct-v0:1\",\n",
      "  \"modelId\": \"mistral.mixtral-8x7b-instruct-v0:1\",\n",
      "  \"modelName\": \"Mixtral 8x7B Instruct\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral Large (24.02)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-large-2402-v1:0\",\n",
      "  \"modelId\": \"mistral.mistral-large-2402-v1:0\",\n",
      "  \"modelName\": \"Mistral Large (24.02)\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Mistral Small (24.02)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.mistral-small-2402-v1:0\",\n",
      "  \"modelId\": \"mistral.mistral-small-2402-v1:0\",\n",
      "  \"modelName\": \"Mistral Small (24.02)\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"ON_DEMAND\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n",
      "Model: Pixtral Large (25.02)\n",
      "{\n",
      "  \"modelArn\": \"arn:aws:bedrock:us-east-1::foundation-model/mistral.pixtral-large-2502-v1:0\",\n",
      "  \"modelId\": \"mistral.pixtral-large-2502-v1:0\",\n",
      "  \"modelName\": \"Pixtral Large (25.02)\",\n",
      "  \"providerName\": \"Mistral AI\",\n",
      "  \"inputModalities\": [\n",
      "    \"TEXT\",\n",
      "    \"IMAGE\"\n",
      "  ],\n",
      "  \"outputModalities\": [\n",
      "    \"TEXT\"\n",
      "  ],\n",
      "  \"responseStreamingSupported\": true,\n",
      "  \"customizationsSupported\": [],\n",
      "  \"inferenceTypesSupported\": [\n",
      "    \"INFERENCE_PROFILE\"\n",
      "  ],\n",
      "  \"modelLifecycle\": {\n",
      "    \"status\": \"ACTIVE\"\n",
      "  }\n",
      "}\n",
      "---------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lists the available Amazon Bedrock models in an &AWS-Region;.\n",
    "\"\"\"\n",
    "import logging\n",
    "import json\n",
    "import boto3\n",
    "\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def list_foundation_models(bedrock_client):\n",
    "    \"\"\"\n",
    "    Gets a list of available Amazon Bedrock foundation models.\n",
    "\n",
    "    :return: The list of available bedrock foundation models.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = bedrock_client.list_foundation_models()\n",
    "        models = response[\"modelSummaries\"]\n",
    "        logger.info(\"Got %s foundation models.\", len(models))\n",
    "        return models\n",
    "\n",
    "    except ClientError:\n",
    "        logger.error(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Entry point for the example. Change aws_region to the &AWS-Region;\n",
    "    that you want to use.\"\"\"\n",
    "   \n",
    "    aws_region = \"us-east-1\"\n",
    "\n",
    "    bedrock_client = boto3.client(service_name=\"bedrock\", region_name=aws_region)\n",
    "    \n",
    "    fm_models = list_foundation_models(bedrock_client)\n",
    "    for model in fm_models:\n",
    "        print(f\"Model: {model[\"modelName\"]}\")\n",
    "        print(json.dumps(model, indent=2))\n",
    "        print(\"---------------------------\\n\")\n",
    "    \n",
    "    logger.info(\"Done.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e3d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The purpose of a 'hello world' program is to serve as a simple and straightforward introduction to a programming language or development environment, demonstrating the basic syntax and execution of a basic program.\n"
     ]
    }
   ],
   "source": [
    "# Use the native inference API to send a text message to Anthropic Claude.\n",
    "\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "# Create a Bedrock Runtime client in the AWS Region of your choice.\n",
    "client = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "# Set the model ID, e.g., Claude 3 Haiku.\n",
    "model_id = \"anthropic.claude-3-haiku-20240307-v1:0\"\n",
    "\n",
    "\n",
    "\n",
    "# Define the prompt for the model.\n",
    "prompt = \"Describe the purpose of a 'hello world' program in one line.\"\n",
    "\n",
    "# Format the request payload using the model's native structure.\n",
    "native_request = {\n",
    "    \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "    \"max_tokens\": 512,\n",
    "    \"temperature\": 0.5,\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [{\"type\": \"text\", \"text\": prompt}],\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Convert the native request to JSON.\n",
    "request = json.dumps(native_request)\n",
    "\n",
    "try:\n",
    "    # Invoke the model with the request.\n",
    "    response = client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)\n",
    "\n",
    "# Decode the response body.\n",
    "model_response = json.loads(response[\"body\"].read())\n",
    "\n",
    "# Extract and print the response text.\n",
    "response_text = model_response[\"content\"][0][\"text\"]\n",
    "print(response_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "946a8087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interact_with_bedrock_model(model_id,prompt,temperature):\n",
    "\n",
    "    'generates response interacting with bedrock models'\n",
    "\n",
    "    # Format the request payload using the model's native structure.\n",
    "    native_request = {\n",
    "        \"inputText\": prompt,\n",
    "        \"textGenerationConfig\": {\n",
    "            \"maxTokenCount\": 512,\n",
    "            \"temperature\": 0.5,\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "    request = json.dumps(native_request)\n",
    "\n",
    "\n",
    "    response = client.invoke_model(modelId=model_id, body=request)\n",
    "\n",
    "    response_text = model_response[\"content\"][0][\"text\"]\n",
    "\n",
    "    return response_text\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9b05e113",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "bedrock = boto3.client(\"bedrock\", region_name=\"us-east-1\")\n",
    "\n",
    "response = bedrock.list_foundation_models()\n",
    "models = response[\"modelSummaries\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50bc55c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "active_models = [\n",
    "    m for m in models\n",
    "    if m.get(\"modelLifecycle\", {}).get(\"status\") == \"ACTIVE\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "de4f23cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = {}\n",
    "\n",
    "for model in active_models:\n",
    "    provider = model[\"providerName\"]\n",
    "\n",
    "    if provider not in selected_models:\n",
    "        selected_models[provider] = model[\"modelId\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "77d9c82b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon Titan: amazon.nova-2-multimodal-embeddings-v1:0\n",
      "Anthropic Claude: anthropic.claude-sonnet-4-20250514-v1:0\n",
      "Meta Llama: meta.llama3-8b-instruct-v1:0\n",
      "Mistral: mistral.voxtral-mini-3b-2507\n"
     ]
    }
   ],
   "source": [
    "final_selection = {\n",
    "    \"Amazon Titan\": selected_models.get(\"Amazon\"),\n",
    "    \"Anthropic Claude\": selected_models.get(\"Anthropic\"),\n",
    "    \"Meta Llama\": selected_models.get(\"Meta\"),\n",
    "    \"Mistral\": selected_models.get(\"Mistral AI\")\n",
    "}\n",
    "\n",
    "for category, model_id in final_selection.items():\n",
    "    print(f\"{category}: {model_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958dcef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5afe47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ada49c2c",
   "metadata": {},
   "source": [
    "### DEMO 1  Same Prompt, Different Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "674af402",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ''' \n",
    "You are an expert technical writer.\n",
    "\n",
    "Task:\n",
    "Summarize the following content for a cloud engineering audience.\n",
    "\n",
    "Constraints:\n",
    "- Maximum 5 bullet points\n",
    "- Keep it concise\n",
    "- Focus on key benefits\n",
    "\n",
    "Content:\n",
    "\"\"\"\n",
    "Amazon Bedrock is a fully managed service that provides access to\n",
    "foundation models via a single API. It enables developers to build\n",
    "Generative AI applications without managing infrastructure...\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba4fee7c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationException",
     "evalue": "An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: required key [prompt] not found#: extraneous key [inputText] is not permitted#: extraneous key [textGenerationConfig] is not permitted, please reformat your input and try again.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationException\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m model_id = \u001b[33m'\u001b[39m\u001b[33mmeta.llama3-8b-instruct-v1:0\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      3\u001b[39m temperature = \u001b[32m0.2\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43minteract_with_bedrock_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36minteract_with_bedrock_model\u001b[39m\u001b[34m(model_id, prompt, temperature)\u001b[39m\n\u001b[32m      6\u001b[39m native_request = {\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minputText\u001b[39m\u001b[33m\"\u001b[39m: prompt,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtextGenerationConfig\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     },\n\u001b[32m     12\u001b[39m }\n\u001b[32m     15\u001b[39m request = json.dumps(native_request)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodelId\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m response_text = model_response[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response_text\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Courses/genai_aws/venv/lib/python3.12/site-packages/botocore/client.py:602\u001b[39m, in \u001b[36mClientCreator._create_api_method.<locals>._api_call\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    598\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    599\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpy_operation_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m() only accepts keyword arguments.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    600\u001b[39m     )\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# The \"self\" in this scope is referring to the BaseClient.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m602\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_api_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43moperation_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Courses/genai_aws/venv/lib/python3.12/site-packages/botocore/context.py:123\u001b[39m, in \u001b[36mwith_current_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hook:\n\u001b[32m    122\u001b[39m     hook()\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Courses/genai_aws/venv/lib/python3.12/site-packages/botocore/client.py:1078\u001b[39m, in \u001b[36mBaseClient._make_api_call\u001b[39m\u001b[34m(self, operation_name, api_params)\u001b[39m\n\u001b[32m   1074\u001b[39m     error_code = request_context.get(\n\u001b[32m   1075\u001b[39m         \u001b[33m'\u001b[39m\u001b[33merror_code_override\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1076\u001b[39m     ) \u001b[38;5;129;01mor\u001b[39;00m error_info.get(\u001b[33m\"\u001b[39m\u001b[33mCode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1077\u001b[39m     error_class = \u001b[38;5;28mself\u001b[39m.exceptions.from_code(error_code)\n\u001b[32m-> \u001b[39m\u001b[32m1078\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(parsed_response, operation_name)\n\u001b[32m   1079\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1080\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parsed_response\n",
      "\u001b[31mValidationException\u001b[39m: An error occurred (ValidationException) when calling the InvokeModel operation: Malformed input request: #: required key [prompt] not found#: extraneous key [inputText] is not permitted#: extraneous key [textGenerationConfig] is not permitted, please reformat your input and try again."
     ]
    }
   ],
   "source": [
    "model_id = 'meta.llama3-8b-instruct-v1:0'\n",
    "\n",
    "temperature = 0.2\n",
    "\n",
    "\n",
    "print(interact_with_bedrock_model(model_id,prompt,temperature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2961494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error invoking model: An error occurred (ResourceNotFoundException) when calling the InvokeModel operation: This model version has reached the end of its life. Please refer to the AWS documentation for more details.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "# Ensure you have the correct IAM permissions (bedrock:InvokeModel)\n",
    "# and model access is granted in the AWS console.\n",
    "\n",
    "def invoke_bedrock_model(prompt, model_id='anthropic.claude-v2'):\n",
    "    \"\"\"\n",
    "    Invokes a specified Amazon Bedrock model with a given prompt.\n",
    "\n",
    "    :param prompt: The prompt to send to the model.\n",
    "    :param model_id: The ID of the model to use.\n",
    "    :return: The generated response text.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the bedrock-runtime client\n",
    "        client = boto3.client('bedrock-runtime', region_name='us-east-1')\n",
    "\n",
    "        # The request body format varies by model.\n",
    "        # This example is for Anthropic Claude models.\n",
    "        body = json.dumps({\n",
    "            \"prompt\": f\"Human: {prompt}\\n\\nAssistant:\",\n",
    "            \"temperature\": 0.5\n",
    "        })\n",
    "\n",
    "        response = client.invoke_model(\n",
    "            body=body,\n",
    "            modelId=model_id,\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "\n",
    "        response_body = json.loads(response.get('body').read())\n",
    "        return response_body.get('completion')\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking model: {e}\")\n",
    "        return None\n",
    "\n",
    "# Example usage\n",
    "prompt = \"What is the capital of France?\"\n",
    "response_text = invoke_bedrock_model(prompt,'amazon.titan-tg1-large')\n",
    "if response_text:\n",
    "    print(f\"Model Response: {response_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95efda24",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e4c6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "bedrock = boto3.client(\"bedrock-runtime\", region_name=\"us-east-1\")\n",
    "\n",
    "\n",
    "def invoke_bedrock(model_id: str, prompt: str, temperature: float = 0.5):\n",
    "    \"\"\"\n",
    "    Unified Bedrock invocation for Titan, Claude, Llama, and Mistral\n",
    "    \"\"\"\n",
    "\n",
    "    # -------- Payload Builder -------- #\n",
    "    if \"amazon.titan\" in model_id:\n",
    "        body = {\n",
    "            \"inputText\": prompt,\n",
    "            \"textGenerationConfig\": {\n",
    "                \"temperature\": temperature,\n",
    "                \"maxTokenCount\": 300,\n",
    "                \"topP\": 0.9\n",
    "            }\n",
    "        }\n",
    "\n",
    "    elif \"anthropic.claude\" in model_id:\n",
    "        body = {\n",
    "            \"prompt\": f\"\\n\\nHuman: {prompt}\\n\\nAssistant:\",\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens_to_sample\": 300\n",
    "        }\n",
    "\n",
    "    elif \"meta.llama\" in model_id:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_gen_len\": 300\n",
    "        }\n",
    "\n",
    "    elif \"mistral\" in model_id:\n",
    "        body = {\n",
    "            \"prompt\": prompt,\n",
    "            \"temperature\": temperature,\n",
    "            \"max_tokens\": 300\n",
    "        }\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_id}\")\n",
    "\n",
    "    # -------- Invoke Model -------- #\n",
    "    response = bedrock.invoke_model(\n",
    "        modelId=model_id,\n",
    "        body=json.dumps(body),\n",
    "        contentType=\"application/json\",\n",
    "        accept=\"application/json\"\n",
    "    )\n",
    "\n",
    "    response_body = json.loads(response[\"body\"].read())\n",
    "\n",
    "    # -------- Normalize Output -------- #\n",
    "    if \"amazon.titan\" in model_id:\n",
    "        return response_body[\"results\"][0][\"outputText\"]\n",
    "\n",
    "    elif \"anthropic.claude\" in model_id:\n",
    "        return response_body[\"completion\"]\n",
    "\n",
    "    elif \"meta.llama\" in model_id:\n",
    "        return response_body[\"generation\"]\n",
    "\n",
    "    elif \"mistral\" in model_id:\n",
    "        return response_body[\"outputs\"][0][\"text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a84b7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- anthropic.claude-3.5-sonnet-20240620-v1:0 ---\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Bedrock' object has no attribute 'invoke_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m--- \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ---\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[43minvoke_bedrock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 48\u001b[39m, in \u001b[36minvoke_bedrock\u001b[39m\u001b[34m(model_id, prompt, temperature)\u001b[39m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;66;03m# -------- Invoke Model -------- #\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m response = \u001b[43mbedrock\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke_model\u001b[49m(\n\u001b[32m     49\u001b[39m     modelId=model_id,\n\u001b[32m     50\u001b[39m     body=json.dumps(body),\n\u001b[32m     51\u001b[39m     contentType=\u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     52\u001b[39m     accept=\u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     53\u001b[39m )\n\u001b[32m     55\u001b[39m response_body = json.loads(response[\u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m].read())\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# -------- Normalize Output -------- #\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Courses/genai_aws/venv/lib/python3.12/site-packages/botocore/client.py:969\u001b[39m, in \u001b[36mBaseClient.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    966\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    967\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m event_response\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m    970\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    971\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'Bedrock' object has no attribute 'invoke_model'"
     ]
    }
   ],
   "source": [
    "prompt = \"Summarize Amazon Bedrock in 3 bullet points.\"\n",
    "\n",
    "models = {'titan': 'amazon.titan-tg1-large', \n",
    "'claude': 'anthropic.claude-sonnet-4-20250514-v1:0', \n",
    "'llama': 'meta.llama3-8b-instruct-v1:0', \n",
    "'mistral': 'mistral.voxtral-mini-3b-2507'}\n",
    "\n",
    "for model,model_id in models.items():\n",
    "    print(f\"\\n--- {model} ---\")\n",
    "    print(invoke_bedrock(model_id, prompt, temperature=0.3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50acd0b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
